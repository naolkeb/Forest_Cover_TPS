{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d30788b2",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; background-color: #222; text-align: center\">\n",
    "<br><br>\n",
    "\n",
    "<h1 style=\"color: white; font-weight: bold;\">\n",
    "    Project\n",
    "</h1>\n",
    "    \n",
    "<h3 style=\"color: #ef7d22; font-weight: normal;\">\n",
    "    Deep and Cross NN (Keras)\n",
    "</h3>\n",
    "\n",
    "<br><br> \n",
    "</div>\n",
    "\n",
    "![orange-divider](https://user-images.githubusercontent.com/7065401/98619088-44ab6000-22e1-11eb-8f6d-5532e68ab274.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782a4366",
   "metadata": {},
   "source": [
    "## Import & Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecf8a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8be938a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(tf. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01868305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3189</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>3270</td>\n",
       "      <td>206</td>\n",
       "      <td>234</td>\n",
       "      <td>193</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3026</td>\n",
       "      <td>182</td>\n",
       "      <td>5</td>\n",
       "      <td>280</td>\n",
       "      <td>29</td>\n",
       "      <td>3270</td>\n",
       "      <td>233</td>\n",
       "      <td>240</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3106</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>351</td>\n",
       "      <td>37</td>\n",
       "      <td>2914</td>\n",
       "      <td>208</td>\n",
       "      <td>234</td>\n",
       "      <td>137</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3022</td>\n",
       "      <td>276</td>\n",
       "      <td>13</td>\n",
       "      <td>192</td>\n",
       "      <td>16</td>\n",
       "      <td>3034</td>\n",
       "      <td>207</td>\n",
       "      <td>238</td>\n",
       "      <td>156</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2906</td>\n",
       "      <td>186</td>\n",
       "      <td>13</td>\n",
       "      <td>266</td>\n",
       "      <td>22</td>\n",
       "      <td>2916</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>154</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0   0       3189      40      8                                30   \n",
       "1   1       3026     182      5                               280   \n",
       "2   2       3106      13      7                               351   \n",
       "3   3       3022     276     13                               192   \n",
       "4   4       2906     186     13                               266   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                              13                             3270   \n",
       "1                              29                             3270   \n",
       "2                              37                             2914   \n",
       "3                              16                             3034   \n",
       "4                              22                             2916   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  ...  Soil_Type32  \\\n",
       "0            206             234            193  ...            0   \n",
       "1            233             240            106  ...            0   \n",
       "2            208             234            137  ...            0   \n",
       "3            207             238            156  ...            0   \n",
       "4            231             231            154  ...            0   \n",
       "\n",
       "   Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type38  Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0            0           1  \n",
       "1            0            0            0           2  \n",
       "2            0            0            0           1  \n",
       "3            0            0            0           2  \n",
       "4            0            0            0           2  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_play_train = pd.read_csv('train.csv')\n",
    "df_play_test = pd.read_csv('test.csv')\n",
    "df_psuedolabels = pd.read_csv('tps12-pseudolabels_v2.csv')\n",
    "\n",
    "df_play_train = pd.concat([df_play_train, df_psuedolabels], axis = 0)\n",
    "df_play_train.reset_index(drop = True)\n",
    "\n",
    "df_play_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcb42329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_play_train['Cover_Type'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f3e6383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type31</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.500000e+06</td>\n",
       "      <td>2969.602410</td>\n",
       "      <td>152.231636</td>\n",
       "      <td>14.923460</td>\n",
       "      <td>264.368149</td>\n",
       "      <td>51.480362</td>\n",
       "      <td>1713.507869</td>\n",
       "      <td>211.659709</td>\n",
       "      <td>221.476154</td>\n",
       "      <td>139.861454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029638</td>\n",
       "      <td>0.043415</td>\n",
       "      <td>0.040606</td>\n",
       "      <td>0.012155</td>\n",
       "      <td>0.015766</td>\n",
       "      <td>0.010695</td>\n",
       "      <td>0.012063</td>\n",
       "      <td>0.043393</td>\n",
       "      <td>0.039841</td>\n",
       "      <td>0.032778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.886753e+05</td>\n",
       "      <td>342.676046</td>\n",
       "      <td>111.629725</td>\n",
       "      <td>8.457005</td>\n",
       "      <td>227.971753</td>\n",
       "      <td>68.520188</td>\n",
       "      <td>1374.922218</td>\n",
       "      <td>31.280435</td>\n",
       "      <td>21.951950</td>\n",
       "      <td>45.398002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169587</td>\n",
       "      <td>0.203790</td>\n",
       "      <td>0.197376</td>\n",
       "      <td>0.109578</td>\n",
       "      <td>0.124569</td>\n",
       "      <td>0.102862</td>\n",
       "      <td>0.109167</td>\n",
       "      <td>0.203740</td>\n",
       "      <td>0.195586</td>\n",
       "      <td>0.178055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000e+06</td>\n",
       "      <td>1782.000000</td>\n",
       "      <td>-33.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-136.000000</td>\n",
       "      <td>-329.000000</td>\n",
       "      <td>-264.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>-51.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.250000e+06</td>\n",
       "      <td>2725.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>751.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.500000e+06</td>\n",
       "      <td>2968.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1320.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.749999e+06</td>\n",
       "      <td>3245.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>2261.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.999999e+06</td>\n",
       "      <td>4359.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>1583.000000</td>\n",
       "      <td>634.000000</td>\n",
       "      <td>7653.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id       Elevation          Aspect           Slope  \\\n",
       "count  1.000000e+06  1000000.000000  1000000.000000  1000000.000000   \n",
       "mean   4.500000e+06     2969.602410      152.231636       14.923460   \n",
       "std    2.886753e+05      342.676046      111.629725        8.457005   \n",
       "min    4.000000e+06     1782.000000      -33.000000       -3.000000   \n",
       "25%    4.250000e+06     2725.000000       59.000000        9.000000   \n",
       "50%    4.500000e+06     2968.000000      124.000000       14.000000   \n",
       "75%    4.749999e+06     3245.000000      251.000000       20.000000   \n",
       "max    4.999999e+06     4359.000000      400.000000       63.000000   \n",
       "\n",
       "       Horizontal_Distance_To_Hydrology  Vertical_Distance_To_Hydrology  \\\n",
       "count                    1000000.000000                  1000000.000000   \n",
       "mean                         264.368149                       51.480362   \n",
       "std                          227.971753                       68.520188   \n",
       "min                         -136.000000                     -329.000000   \n",
       "25%                          102.000000                        3.000000   \n",
       "50%                          206.000000                       31.000000   \n",
       "75%                          356.000000                       78.000000   \n",
       "max                         1583.000000                      634.000000   \n",
       "\n",
       "       Horizontal_Distance_To_Roadways   Hillshade_9am  Hillshade_Noon  \\\n",
       "count                   1000000.000000  1000000.000000  1000000.000000   \n",
       "mean                       1713.507869      211.659709      221.476154   \n",
       "std                        1374.922218       31.280435       21.951950   \n",
       "min                        -264.000000        1.000000       53.000000   \n",
       "25%                         751.000000      197.000000      210.000000   \n",
       "50%                        1320.000000      218.000000      224.000000   \n",
       "75%                        2261.000000      234.000000      237.000000   \n",
       "max                        7653.000000      296.000000      276.000000   \n",
       "\n",
       "        Hillshade_3pm  ...     Soil_Type31     Soil_Type32     Soil_Type33  \\\n",
       "count  1000000.000000  ...  1000000.000000  1000000.000000  1000000.000000   \n",
       "mean       139.861454  ...        0.029638        0.043415        0.040606   \n",
       "std         45.398002  ...        0.169587        0.203790        0.197376   \n",
       "min        -51.000000  ...        0.000000        0.000000        0.000000   \n",
       "25%        114.000000  ...        0.000000        0.000000        0.000000   \n",
       "50%        142.000000  ...        0.000000        0.000000        0.000000   \n",
       "75%        169.000000  ...        0.000000        0.000000        0.000000   \n",
       "max        270.000000  ...        1.000000        1.000000        1.000000   \n",
       "\n",
       "          Soil_Type34     Soil_Type35     Soil_Type36     Soil_Type37  \\\n",
       "count  1000000.000000  1000000.000000  1000000.000000  1000000.000000   \n",
       "mean         0.012155        0.015766        0.010695        0.012063   \n",
       "std          0.109578        0.124569        0.102862        0.109167   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          0.000000        0.000000        0.000000        0.000000   \n",
       "50%          0.000000        0.000000        0.000000        0.000000   \n",
       "75%          0.000000        0.000000        0.000000        0.000000   \n",
       "max          1.000000        1.000000        1.000000        1.000000   \n",
       "\n",
       "          Soil_Type38     Soil_Type39     Soil_Type40  \n",
       "count  1000000.000000  1000000.000000  1000000.000000  \n",
       "mean         0.043393        0.039841        0.032778  \n",
       "std          0.203740        0.195586        0.178055  \n",
       "min          0.000000        0.000000        0.000000  \n",
       "25%          0.000000        0.000000        0.000000  \n",
       "50%          0.000000        0.000000        0.000000  \n",
       "75%          0.000000        0.000000        0.000000  \n",
       "max          1.000000        1.000000        1.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_play_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f187d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4984711 entries, 0 to 984710\n",
      "Data columns (total 56 columns):\n",
      " #   Column                              Dtype\n",
      "---  ------                              -----\n",
      " 0   Id                                  int64\n",
      " 1   Elevation                           int64\n",
      " 2   Aspect                              int64\n",
      " 3   Slope                               int64\n",
      " 4   Horizontal_Distance_To_Hydrology    int64\n",
      " 5   Vertical_Distance_To_Hydrology      int64\n",
      " 6   Horizontal_Distance_To_Roadways     int64\n",
      " 7   Hillshade_9am                       int64\n",
      " 8   Hillshade_Noon                      int64\n",
      " 9   Hillshade_3pm                       int64\n",
      " 10  Horizontal_Distance_To_Fire_Points  int64\n",
      " 11  Wilderness_Area1                    int64\n",
      " 12  Wilderness_Area2                    int64\n",
      " 13  Wilderness_Area3                    int64\n",
      " 14  Wilderness_Area4                    int64\n",
      " 15  Soil_Type1                          int64\n",
      " 16  Soil_Type2                          int64\n",
      " 17  Soil_Type3                          int64\n",
      " 18  Soil_Type4                          int64\n",
      " 19  Soil_Type5                          int64\n",
      " 20  Soil_Type6                          int64\n",
      " 21  Soil_Type7                          int64\n",
      " 22  Soil_Type8                          int64\n",
      " 23  Soil_Type9                          int64\n",
      " 24  Soil_Type10                         int64\n",
      " 25  Soil_Type11                         int64\n",
      " 26  Soil_Type12                         int64\n",
      " 27  Soil_Type13                         int64\n",
      " 28  Soil_Type14                         int64\n",
      " 29  Soil_Type15                         int64\n",
      " 30  Soil_Type16                         int64\n",
      " 31  Soil_Type17                         int64\n",
      " 32  Soil_Type18                         int64\n",
      " 33  Soil_Type19                         int64\n",
      " 34  Soil_Type20                         int64\n",
      " 35  Soil_Type21                         int64\n",
      " 36  Soil_Type22                         int64\n",
      " 37  Soil_Type23                         int64\n",
      " 38  Soil_Type24                         int64\n",
      " 39  Soil_Type25                         int64\n",
      " 40  Soil_Type26                         int64\n",
      " 41  Soil_Type27                         int64\n",
      " 42  Soil_Type28                         int64\n",
      " 43  Soil_Type29                         int64\n",
      " 44  Soil_Type30                         int64\n",
      " 45  Soil_Type31                         int64\n",
      " 46  Soil_Type32                         int64\n",
      " 47  Soil_Type33                         int64\n",
      " 48  Soil_Type34                         int64\n",
      " 49  Soil_Type35                         int64\n",
      " 50  Soil_Type36                         int64\n",
      " 51  Soil_Type37                         int64\n",
      " 52  Soil_Type38                         int64\n",
      " 53  Soil_Type39                         int64\n",
      " 54  Soil_Type40                         int64\n",
      " 55  Cover_Type                          int64\n",
      "dtypes: int64(56)\n",
      "memory usage: 2.1 GB\n"
     ]
    }
   ],
   "source": [
    "df_play_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342e1043",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "455cdd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play_train[\"Aspect\"][df_play_train[\"Aspect\"] < 0] += 360\n",
    "df_play_train[\"Aspect\"][df_play_train[\"Aspect\"] > 359] -= 360\n",
    "\n",
    "df_play_test[\"Aspect\"][df_play_test[\"Aspect\"] < 0] += 360\n",
    "df_play_test[\"Aspect\"][df_play_test[\"Aspect\"] > 359] -= 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d49d4641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play_train.loc[df_play_train[\"Hillshade_9am\"] < 0, \"Hillshade_9am\"] = 0\n",
    "df_play_test.loc[df_play_test[\"Hillshade_9am\"] < 0, \"Hillshade_9am\"] = 0\n",
    "\n",
    "df_play_train.loc[df_play_train[\"Hillshade_Noon\"] < 0, \"Hillshade_Noon\"] = 0\n",
    "df_play_test.loc[df_play_test[\"Hillshade_Noon\"] < 0, \"Hillshade_Noon\"] = 0\n",
    "\n",
    "df_play_train.loc[df_play_train[\"Hillshade_3pm\"] < 0, \"Hillshade_3pm\"] = 0\n",
    "df_play_test.loc[df_play_test[\"Hillshade_3pm\"] < 0, \"Hillshade_3pm\"] = 0\n",
    "\n",
    "df_play_train.loc[df_play_train[\"Hillshade_9am\"] > 255, \"Hillshade_9am\"] = 255\n",
    "df_play_test.loc[df_play_test[\"Hillshade_9am\"] > 255, \"Hillshade_9am\"] = 255\n",
    "\n",
    "df_play_train.loc[df_play_train[\"Hillshade_Noon\"] > 255, \"Hillshade_Noon\"] = 255\n",
    "df_play_test.loc[df_play_test[\"Hillshade_Noon\"] > 255, \"Hillshade_Noon\"] = 255\n",
    "\n",
    "df_play_train.loc[df_play_train[\"Hillshade_3pm\"] > 255, \"Hillshade_3pm\"] = 255\n",
    "df_play_test.loc[df_play_test[\"Hillshade_3pm\"] > 255, \"Hillshade_3pm\"] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "580e06c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play_test['Euclid_Dist_To_Hyrdo'] = np.sqrt(df_play_test['Horizontal_Distance_To_Hydrology']**2 + \n",
    "                               df_play_test['Vertical_Distance_To_Hydrology']**2)\n",
    "df_play_train['Euclid_Dist_To_Hyrdo'] = np.sqrt(df_play_train['Horizontal_Distance_To_Hydrology']**2 + \n",
    "                               df_play_train['Vertical_Distance_To_Hydrology']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b8dacb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play_test['Mhtn_Dist_To_Hydro'] = np.abs(df_play_test['Horizontal_Distance_To_Hydrology']) + np.abs(df_play_test['Vertical_Distance_To_Hydrology'])\n",
    "df_play_train['Mhtn_Dist_To_Hydro'] = np.abs(df_play_train['Horizontal_Distance_To_Hydrology']) + np.abs(df_play_train['Vertical_Distance_To_Hydrology'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9587c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_Hillshade = ['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']\n",
    "soil_features = [x for x in df_play_train.columns if x.startswith(\"Soil_Type\")]\n",
    "wilderness_features = [x for x in df_play_train.columns if x.startswith(\"Wilderness_Area\")]\n",
    "\n",
    "def addFeature(X):\n",
    "    # Thanks @mpwolke : https://www.kaggle.com/mpwolke/tooezy-where-are-you-no-camping-here\n",
    "    X[\"Soil_Count\"] = X[soil_features].apply(sum, axis=1)\n",
    "\n",
    "    # Thanks @yannbarthelemy : https://www.kaggle.com/yannbarthelemy/tps-december-first-simple-feature-engineering\n",
    "    X[\"Wilderness_Area_Count\"] = X[wilderness_features].apply(sum, axis=1)\n",
    "    X[\"Hillshade_mean\"] = X[features_Hillshade].mean(axis=1)\n",
    "    X['amp_Hillshade'] = X[features_Hillshade].max(axis=1) - X[features_Hillshade].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c74ffa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "addFeature(df_play_train)\n",
    "addFeature(df_play_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf3b8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play_test.drop(['Soil_Type7','Soil_Type15','Id'], axis=1, inplace=True)\n",
    "df_play_train.drop(['Soil_Type7','Soil_Type15','Id'], axis=1, inplace=True)\n",
    "\n",
    "df_play_train = df_play_train[df_play_train.Cover_Type != 5]\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df_play_train[\"Cover_Type\"] = encoder.fit_transform(df_play_train[\"Cover_Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da6b20a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "X = df_play_train.drop(['Cover_Type'],axis=1)\n",
    "y = df_play_train['Cover_Type']\n",
    "\n",
    "le = LabelEncoder()\n",
    "target = to_categorical(le.fit_transform(y))\n",
    "X_test = df_play_test\n",
    "\n",
    "del df_play_train,df_play_test,df_psuedolabels,encoder,wilderness_features,soil_features,features_Hillshade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4727b961",
   "metadata": {},
   "source": [
    "#### Reducing Memory usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "332c3d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int8','int16','int32','int64','float16','float32','float64']\n",
    "    start_mem = df.memory_usage().sum() / 1042**2\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        \n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            \n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "                    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    \n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9d94a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 394.56 Mb (81.8% reduction)\n",
      "Mem. usage decreased to 71.53 Mb (83.3% reduction)\n"
     ]
    }
   ],
   "source": [
    "X = reduce_mem_usage(X)\n",
    "X_test = reduce_mem_usage(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16297f40",
   "metadata": {},
   "source": [
    "## Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bee1c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"Elevation\",\n",
    "    \"Aspect\",\n",
    "    \"Mhtn_Dist_To_Hydro\",\n",
    "    \"Euclid_Dist_To_Hyrdo\",\n",
    "    \"Slope\",\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "    \n",
    "    \"Soil_Count\",\"Wilderness_Area_Count\",\"Hillshade_mean\",\"amp_Hillshade\"\n",
    "]\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X[cols] = scaler.fit_transform(X[cols])\n",
    "X_test[cols] = scaler.transform(X_test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ed97c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "del scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ce925",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "338182ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper functions\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    print(f\"Seed set to: {seed}\")\n",
    "\n",
    "def plot_eval_results(scores, n_splits):\n",
    "    cols = 5\n",
    "    rows = int(np.ceil(n_splits/cols))\n",
    "    \n",
    "    fig, ax = plt.subplots(rows, cols, tight_layout=True, figsize=(20,2.5))\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    for fold in range(len(scores)):\n",
    "        df_eval = pd.DataFrame({'train_loss': scores[fold]['loss'], 'valid_loss': scores[fold]['val_loss']})\n",
    "\n",
    "        sns.lineplot(\n",
    "            x=df_eval.index,\n",
    "            y=df_eval['train_loss'],\n",
    "            label='train_loss',\n",
    "            ax=ax[fold]\n",
    "        )\n",
    "\n",
    "        sns.lineplot(\n",
    "            x=df_eval.index,\n",
    "            y=df_eval['valid_loss'],\n",
    "            label='valid_loss',\n",
    "            ax=ax[fold]\n",
    "        )\n",
    "\n",
    "        ax[fold].set_ylabel('')\n",
    "\n",
    "    sns.despine()\n",
    "\n",
    "def plot_cm(cm):\n",
    "    metrics = {\n",
    "        'accuracy': cm / cm.sum(),\n",
    "        'recall' : cm / cm.sum(axis=1),\n",
    "        'precision': cm / cm.sum(axis=0)\n",
    "    }\n",
    "    \n",
    "    fig, ax = plt.subplots(1,3, tight_layout=True, figsize=(15,5))\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    mask = (np.eye(cm.shape[0]) == 0) * 1\n",
    "\n",
    "    for idx, (name, matrix) in enumerate(metrics.items()):\n",
    "\n",
    "        ax[idx].set_title(name)\n",
    "\n",
    "        sns.heatmap(\n",
    "            data=matrix,\n",
    "            cmap=sns.dark_palette(\"#69d\", reverse=True, as_cmap=True),\n",
    "            cbar=False,\n",
    "            mask=mask,\n",
    "            lw=0.25,\n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            ax=ax[idx]\n",
    "        )\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84c7d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = X_test.shape[1:]\n",
    "NUM_CLASSES = y.nunique()\n",
    "KERNEL_INIT = \"lecun_normal\"\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential([\n",
    "        layers.Dense(units=300, kernel_initializer=KERNEL_INIT, activation=\"selu\", input_shape=INPUT_SHAPE),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(units=200, kernel_initializer=KERNEL_INIT, activation=\"selu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(units=100, kernel_initializer=KERNEL_INIT, activation=\"selu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(units=50, kernel_initializer=KERNEL_INIT, activation=\"selu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(units=NUM_CLASSES, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"acc\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be6439f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom dense-block\n",
    "class DenseBlock(layers.Layer):\n",
    "    def __init__(self, units, dropout_rate=0):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(\n",
    "            units,\n",
    "            kernel_initializer=\"lecun_normal\"\n",
    "        )\n",
    "        self.selu = layers.Activation(tf.keras.activations.selu)\n",
    "        self.batchn = layers.BatchNormalization()\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.dense(inputs)\n",
    "        x = self.batchn(x)\n",
    "        x = self.selu(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "# create dense & cross model\n",
    "class CrossNet(tf.keras.Model):\n",
    "    def __init__(self, hidden_layers, dropout_rate=0):\n",
    "        super().__init__()\n",
    "        self.dense_layers = [\n",
    "            DenseBlock(units)\n",
    "            for units in hidden_layers\n",
    "        ]\n",
    "        self.dense = layers.Dense(units=X.shape[-1])\n",
    "        self.concat = layers.Concatenate()\n",
    "        self.batchn = layers.BatchNormalization()\n",
    "        self.softmax = layers.Dense(units=target.shape[-1], activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        dense, cross = inputs, inputs\n",
    "        for dense_layer in self.dense_layers:\n",
    "            #dense\n",
    "            dense = dense_layer(dense)\n",
    "            #cross\n",
    "            cross_current = self.dense(cross)\n",
    "            cross = inputs * cross_current + cross\n",
    "        cross = self.batchn(cross)\n",
    "        merged = self.concat([dense, cross])\n",
    "        return self.softmax(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c17a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", \n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor=\"val_acc\", \n",
    "    patience=10, \n",
    "    verbose=True, \n",
    "    mode=\"max\", \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "callbacks = [lr, es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1324a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "#plot_model(\n",
    "#    build_model(),\n",
    "#    show_shapes=True,\n",
    "#    show_layer_names=True\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bb2bac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on 1 replicas\n",
      "Number of GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "    tf_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    print(\"Running on TPU:\", tpu.master())\n",
    "except:\n",
    "    tf_strategy = tf.distribute.get_strategy()\n",
    "    print(f\"Running on {tf_strategy.num_replicas_in_sync} replicas\")\n",
    "    print(\"Number of GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd85ba1",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "839eee71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to: 2021\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00067: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 1 || Min Val Loss: 0.06694500148296356\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00071: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 2 || Min Val Loss: 0.06585303694009781\n",
      "_________________________________________________________________\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00030: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 3 || Min Val Loss: 0.06977247446775436\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00056: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 4 || Min Val Loss: 0.06612082570791245\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00066: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 5 || Min Val Loss: 0.06566265970468521\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00071: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 6 || Min Val Loss: 0.0676378607749939\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00065: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 7 || Min Val Loss: 0.06762304902076721\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00057: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 8 || Min Val Loss: 0.06740531325340271\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00057: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 9 || Min Val Loss: 0.0675363838672638\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00069: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 10 || Min Val Loss: 0.06717883795499802\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00041: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 11 || Min Val Loss: 0.0678979679942131\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00047: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 12 || Min Val Loss: 0.0672103762626648\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00047: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 13 || Min Val Loss: 0.0665624737739563\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00071: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 14 || Min Val Loss: 0.06696222722530365\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00050: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Fold 15 || Min Val Loss: 0.0672474354505539\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00078: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 16 || Min Val Loss: 0.06629576534032822\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00038: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 17 || Min Val Loss: 0.06808803975582123\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00065: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 18 || Min Val Loss: 0.06709863990545273\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00086: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 19 || Min Val Loss: 0.06552615761756897\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00061: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 20 || Min Val Loss: 0.06666968762874603\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Overall Mean Validation Loss: 0.0670647107064724\n"
     ]
    }
   ],
   "source": [
    "seed = 2021\n",
    "set_seed(seed)\n",
    "\n",
    "FOLDS = 20\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 4096\n",
    "\n",
    "cv = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "predictions = []\n",
    "oof_preds = {'y_valid': list(), 'y_hat': list()}\n",
    "scores_nn = {fold:None for fold in range(cv.n_splits)}\n",
    "\n",
    "\n",
    "for fold, (idx_train, idx_valid) in enumerate(cv.split(X,y)):\n",
    "    X_train, y_train = X.iloc[idx_train], target[idx_train]\n",
    "    X_valid, y_valid = X.iloc[idx_valid], target[idx_valid]\n",
    "    \n",
    "    model = build_model()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        verbose=False,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    scores_nn[fold] = history.history\n",
    "\n",
    "    oof_preds['y_valid'].extend(y.iloc[idx_valid])\n",
    "    oof_preds['y_hat'].extend(model.predict(X_valid, batch_size=BATCH_SIZE))\n",
    "\n",
    "    prediction = model.predict(X_test, batch_size=BATCH_SIZE)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "    del model, prediction\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "\n",
    "    print('_'*65)\n",
    "    print(f\"Fold {fold+1} || Min Val Loss: {np.min(scores_nn[fold]['val_loss'])}\")\n",
    "    print('_'*65)\n",
    "\n",
    "\n",
    "overall_score = [np.min(scores_nn[fold]['val_loss']) for fold in range(cv.n_splits)]\n",
    "print('_'*65)\n",
    "print(f\"Overall Mean Validation Loss: {np.mean(overall_score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9afed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00051: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 1 || Min Val Loss: 0.06854543089866638\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00065: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 2 || Min Val Loss: 0.0669480413198471\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00074: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 3 || Min Val Loss: 0.06630497425794601\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00069: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 4 || Min Val Loss: 0.06626047939062119\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00067: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 5 || Min Val Loss: 0.06688100844621658\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00072: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 6 || Min Val Loss: 0.0687900260090828\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00063: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 7 || Min Val Loss: 0.06832332909107208\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00071: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 8 || Min Val Loss: 0.0675831064581871\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00080: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 9 || Min Val Loss: 0.0669364333152771\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00076: early stopping\n",
      "_________________________________________________________________\n",
      "Fold 10 || Min Val Loss: 0.06762360781431198\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00069: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Fold 11 || Min Val Loss: 0.06683128327131271\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "scores_nn = {fold:None for fold in range(cv.n_splits)}\n",
    "\n",
    "\n",
    "for fold, (idx_train, idx_valid) in enumerate(cv.split(X,y)):\n",
    "    X_train, y_train = X.iloc[idx_train], target[idx_train]\n",
    "    X_valid, y_valid = X.iloc[idx_valid], target[idx_valid]\n",
    "    \n",
    "    with tf_strategy.scope():\n",
    "        model = CrossNet(\n",
    "            hidden_layers=[312, 256, 192, 128, 128],\n",
    "            dropout_rate=0.1\n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "            metrics=['acc']\n",
    "        )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        verbose=False,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    scores_nn[fold] = history.history\n",
    "\n",
    "    oof_preds['y_valid'].extend(y.iloc[idx_valid])\n",
    "    oof_preds['y_hat'].extend(model.predict(X_valid, batch_size=BATCH_SIZE))\n",
    "\n",
    "    prediction = model.predict(X_test, batch_size=BATCH_SIZE)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "    del model, prediction\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "\n",
    "    print('_'*65)\n",
    "    print(f\"Fold {fold+1} || Min Val Loss: {np.min(scores_nn[fold]['val_loss'])}\")\n",
    "    print('_'*65)\n",
    "\n",
    "\n",
    "overall_score = [np.min(scores_nn[fold]['val_loss']) for fold in range(cv.n_splits)]\n",
    "print('_'*65)\n",
    "print(f\"Overall Mean Validation Loss: {np.mean(overall_score)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5a6c43",
   "metadata": {},
   "source": [
    "## Evaluation & Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537db7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_results(scores_nn, cv.n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f8b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare oof_predictions\n",
    "oof_y_true = np.array(oof_preds['y_valid'])\n",
    "oof_y_hat = le.inverse_transform(np.argmax(oof_preds['y_hat'],axis=1))\n",
    "\n",
    "# create confusion matrix, calculate accuracy, recall & precision\n",
    "cm = pd.DataFrame(data=confusion_matrix(oof_y_true,oof_y_hat, labels= le.classes_), index=le.classes_,columns=le.classes_)\n",
    "plot_cm(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d2134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create final prediction, inverse labels to original classes\n",
    "final_predictions = le.inverse_transform(np.argmax(sum(predictions), axis=1))\n",
    "\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "sample_submission['Cover_Type'] = final_predictions\n",
    "sample_submission.to_csv('submission1.csv', index=False)\n",
    "\n",
    "sns.countplot(final_predictions)\n",
    "sns.despine()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
